{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90e3949-1633-44a9-b17a-ff37e52020f8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb52faa-ef8e-4058-a708-141d81b05f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume2/code/Users/rubchume/VoiceCloningFakeAudioDetection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext extensions\n",
    "%cd_repo_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c308b454-4b83-42b2-9c70-250c913f28a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/cuda/__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "import importlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from typing import Iterable, List\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azureml.core import Workspace, Dataset as AzureCoreDataset, Datastore\n",
    "from IPython.display import Audio\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from pydub import AudioSegment\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "import directory_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283776b1-d4ab-4108-9e0c-715d4e333606",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca665b5c-33bf-471c-bdfb-3aea22746c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce_audio_file_with_pydub(audio_file):\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "    display(audio)\n",
    "    \n",
    "\n",
    "def reproduce_audio_from_pcm_samples(pcm_samples: np.array, sample_rate: int):\n",
    "    audio = Audio(data=pcm_samples, rate=sample_rate, autoplay=True)\n",
    "    display(audio)\n",
    "    \n",
    "\n",
    "def get_relative_path(origin, destination):\n",
    "    go_up_path = \"../\"\n",
    "    \n",
    "    origin_absolute = Path(origin).resolve()\n",
    "    destination_absolute = Path(destination).resolve()\n",
    "    \n",
    "    common_path = Path(os.path.commonpath([origin_absolute, destination_absolute]))\n",
    "    from_origin_to_common_path = Path(go_up_path * (len(origin_absolute.parts) - len(common_path.parts)))\n",
    "    from_common_path_to_destination = destination_absolute.relative_to(common_path)\n",
    "    return from_origin_to_common_path / from_common_path_to_destination\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def suppress_error_print():\n",
    "    original_stderr = sys.stderr\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stderr.close()\n",
    "        sys.stderr = original_stderr\n",
    "\n",
    "\n",
    "def parse_datastore_uri(datastore_uri):\n",
    "    match_object = re.match(\n",
    "        r\"^azureml://subscriptions/[^/]+/resourcegroups/[^/]+/workspaces/[^/]+/datastores/(?P<datastore>[^/]+)/paths/(?P<relative_path>.+)$\",\n",
    "        datastore_uri\n",
    "    )\n",
    "\n",
    "    datastore_name = match_object.group(\"datastore\")\n",
    "    relative_path = match_object.group(\"relative_path\")\n",
    "    return datastore_name, relative_path\n",
    "\n",
    "\n",
    "def mount_data_asset(data_asset):\n",
    "    datastore_name, relative_path = parse_datastore_uri(data_asset.path)\n",
    "    workspace = Workspace.from_config()\n",
    "    datastore = Datastore.get(workspace, datastore_name)\n",
    "    dataset = AzureCoreDataset.File.from_files(path=(datastore, relative_path))\n",
    "    return dataset.mount()\n",
    "    \n",
    "\n",
    "@contextmanager\n",
    "def mounted_data_asset(name, version=None, label=\"latest\"):\n",
    "    ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
    "    data_asset = ml_client.data.get(name=name, version=version, label=label)\n",
    "    \n",
    "    with suppress_error_print():\n",
    "        mounted_path = mount_data_asset(data_asset)\n",
    "        mounted_path.start()\n",
    "\n",
    "    yield mounted_path.mount_point\n",
    "    mounted_path.stop()\n",
    "\n",
    "    \n",
    "import itertools\n",
    "import runpy\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def cli_arguments(**arguments):\n",
    "    original_arguments = sys.argv\n",
    "    sys.argv = kwargs_to_command_line_arguments(**arguments)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.argv = original_arguments\n",
    "\n",
    "\n",
    "def kwargs_to_command_line_arguments(**kwargs):\n",
    "    return [None] + list(itertools.chain.from_iterable([\n",
    "        (f\"--{key}\", str(value))\n",
    "        for key, value in kwargs.items()\n",
    "    ]))\n",
    "\n",
    "\n",
    "class WorkingDirectoryOn:\n",
    "    def __init__(self, working_directory):\n",
    "        self.working_directory = working_directory\n",
    "        self.original_working_directory = os.getcwd()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        os.chdir(self.working_directory)\n",
    "    \n",
    "    def __exit__(self, exception_type, exception_value, traceback):\n",
    "        os.chdir(self.original_working_directory)\n",
    "        \n",
    "        \n",
    "@contextmanager\n",
    "def relative_paths_from(origin, paths):\n",
    "    yield (\n",
    "        get_relative_path(origin, path)\n",
    "        for path in paths\n",
    "    )\n",
    "    \n",
    "    \n",
    "def import_module(module_file):\n",
    "    module_path = str(Path(module_file).with_suffix(\"\")).replace(\"/\", \".\")\n",
    "    data_module = importlib.import_module(module_path)\n",
    "    importlib.reload(data_module)\n",
    "    return data_module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29bd85-afb7-4645-8788-d4a09196df17",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada9344b-25cb-4e55-877a-cc400348bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"classification_wav2vec\"\n",
    "\n",
    "project_source_path = directory_structure.classification_source_path / experiment_name\n",
    "Path(project_source_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "pipeline_path = directory_structure.job_definitions_path / experiment_name\n",
    "Path(pipeline_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "project_source_path_relative = get_relative_path(pipeline_path, project_source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6eb873f-e2fb-45e5-8b53-fe7de8c0a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_voices_path = directory_structure.data_path / \"Common Voice Full/cv-corpus-15.0-2023-09-08/en\"\n",
    "real_voices_info_file = real_voices_path / \"selected.csv\"\n",
    "\n",
    "real_info = pd.read_csv(real_voices_info_file).iloc[:, 0].map(\n",
    "    lambda path: str(real_voices_path / \"clips\" / path)\n",
    ")\n",
    "cloned_info = pd.Series(\n",
    "    [\n",
    "        str(path)\n",
    "        for path in (directory_structure.audio_output_path / \"OOTB-YourTTS/TIMITexamples\").glob(\"*.wav\")\n",
    "    ],\n",
    "    name=\"path\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1d6e5-60b7-40d6-b23d-8666166ab7df",
   "metadata": {},
   "source": [
    "# Step: Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c05a91-4a00-401b-8f1e-02ec0357ccce",
   "metadata": {},
   "source": [
    "## Create script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85247620-09f2-4044-8e2b-ee0499e407b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_common_voice_audio_list_script_name = \"prepare_common_voice_audio_list.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa5a013-06d9-414f-ae30-8b9fd4d9337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/classification/classification_wav2vec/prepare_common_voice_audio_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {project_source_path}/{prepare_common_voice_audio_list_script_name}\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils import make_command\n",
    "\n",
    "\n",
    "@make_command\n",
    "def main(common_voice_dataset, files_info_tsv, audio_files_csv):\n",
    "    validated_tsv_path = Path(common_voice_dataset) / files_info_tsv\n",
    "    pd.read_csv(validated_tsv_path, delimiter=\"\\t\").path.to_csv(audio_files_csv, header=False, index=False)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149173e-13ea-4a3b-be75-ca570fe6ca46",
   "metadata": {},
   "source": [
    "## Test script locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed7d6ff-e354-4757-ad16-f0be1e655c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.modules.pop(\"prepare_common_voice_audio_list\", None)\n",
    "\n",
    "# ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
    "# common_voice_data_asset = ml_client.data.get(name=\"CommonVoiceDeltaSegment15\", label=\"latest\")\n",
    "\n",
    "# with mounted_data_asset(common_voice_data_asset) as common_voice_mount_path:\n",
    "#     with WorkingDirectoryOn(project_source_path):\n",
    "#         with relative_paths_from(\n",
    "#             project_source_path,\n",
    "#             [\"temp/selected.csv\"]\n",
    "#         ) as (audio_files_csv,):\n",
    "#             with cli_arguments(\n",
    "#                 common_voice_dataset=common_voice_mount_path,\n",
    "#                 files_info_tsv=\"en/validated.tsv\",\n",
    "#                 audio_files_csv=audio_files_csv\n",
    "#             ):\n",
    "#                 runpy.run_path(prepare_common_voice_audio_list_script_name, run_name='__main__')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167abed-fadd-48e9-979c-223c44b4aa6d",
   "metadata": {},
   "source": [
    "## Create component definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bb9c9-49e1-4815-b4c1-d6510655cfcf",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5f33a6-4e15-44cf-877b-43d8c65ef7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_environment_name = \"prepare-common-voice-audio-list-environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a748946-1889-4c91-8d32-b57bc5dfe4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job_definitions/environments/prepare-common-voice-audio-list-environment.yaml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%rendertemplate {directory_structure.environments_path}/{prepare_data_environment_name}.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: [[prepare_data_environment_name]]\n",
    "image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n",
    "conda_file: conda.yaml\n",
    "description: Environment created for data preparation in voice classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155d0aa8-b09e-4406-ab32-539d68955bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az ml environment create --file {directory_structure.environments_path}/{prepare_data_environment_name}.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8735c61-6840-4a78-a5eb-9aab0bb67b23",
   "metadata": {},
   "source": [
    "### Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32e7923-3981-49bf-ad94-bdd781129f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_component_name = \"prepare_common_voice_audio_list.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9313621-c261-498a-9c90-17f7866aa5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job_definitions/classification_wav2vec/prepare_common_voice_audio_list.yaml'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%rendertemplate {pipeline_path}/{prepare_data_component_name}\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
    "type: command\n",
    "\n",
    "name: prepare_common_voice_data_for_prediction\n",
    "display_name: Prepare data for prediction\n",
    "\n",
    "inputs:\n",
    "    common_voice_dataset:\n",
    "        type: uri_folder\n",
    "        mode: ro_mount\n",
    "    files_info_tsv:\n",
    "        type: string\n",
    "    \n",
    "outputs:\n",
    "    audio_files_csv:\n",
    "        type: uri_file\n",
    "        mode: rw_mount\n",
    "\n",
    "code: [[project_source_path_relative]]\n",
    "command: >-\n",
    "    python [[prepare_common_voice_audio_list_script_name]]\n",
    "    --common_voice_dataset ${{inputs.common_voice_dataset}}\n",
    "    --files_info_tsv ${{inputs.files_info_tsv}}\n",
    "    --audio_files_csv ${{outputs.audio_files_csv}}\n",
    "\n",
    "environment: azureml:[[prepare_data_environment_name]]@latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac4373-0669-41fa-a889-337fd95b853b",
   "metadata": {},
   "source": [
    "# Step: Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a08603-82ce-4f76-ba0a-f131d777432b",
   "metadata": {},
   "source": [
    "## Create script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d6479fe-031b-43eb-b132-23438963d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/classification/classification_wav2vec/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {project_source_path}/predict.py\n",
    "import argparse\n",
    "import inspect\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from audio_binary_dataset import AudioDumbDataset\n",
    "from cloned_audio_detector import ClonedAudioDetector\n",
    "from utils import get_workspace, mounted_datastore, upload_files_to_datastore\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def make_command(function):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    for parameter_name, parameter in inspect.signature(function).parameters.items():\n",
    "        parser.add_argument(f\"--{parameter_name}\", type=parameter.annotation if parameter.annotation != inspect._empty else None)\n",
    "    \n",
    "    def wrapper():\n",
    "        args, unknown = parser.parse_known_args()\n",
    "        non_null_args = {key: value for key, value in vars(args).items() if value is not None}\n",
    "        return function(**non_null_args)\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def get_model(job_name, download_path):\n",
    "    ws = get_workspace()\n",
    "    ml_client = MLClient(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        subscription_id=ws.subscription_id,\n",
    "        resource_group_name=ws.resource_group,\n",
    "        workspace_name=ws.name,\n",
    "    )\n",
    "    ml_client.jobs.download(\n",
    "        name=job_name,\n",
    "        output_name='checkpoint',\n",
    "        download_path=download_path\n",
    "    )\n",
    "    checkpoint_path = Path(download_path) / \"named-outputs\" / \"checkpoint\" / \"checkpoint\"\n",
    "    detector_loaded = ClonedAudioDetector.load_from_checkpoint(checkpoint_path=checkpoint_path , map_location=device)\n",
    "    detector_loaded.eval();\n",
    "    return detector_loaded\n",
    "\n",
    "\n",
    "def get_file_batch_indices(file):\n",
    "    match = re.match(r\"^logits_batch_(\\d+)_(\\d+)$\", Path(file).stem)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "\n",
    "\n",
    "def predict_macro_batch(model, dataset, predictions_directory, batch_size=100, macro_batch_size=10):\n",
    "    with mounted_datastore(\n",
    "        datastore_name=\"workspaceblobstore\",\n",
    "        relative_path=predictions_directory\n",
    "    ) as predictions_path:\n",
    "        files = pd.Series(Path(predictions_path).iterdir())\n",
    "        \n",
    "    batch_indices = pd.DataFrame(files.map(get_file_batch_indices).dropna().tolist(), columns=[\"batch_size\", \"batch_index\"]).astype(\"int\")\n",
    "    \n",
    "    batch_indices_of_size = batch_indices[batch_indices.batch_size == batch_size].batch_index\n",
    "    if len(batch_indices_of_size) > 0:\n",
    "        last_index = batch_indices_of_size.sort_values(ascending=False).iloc[0]\n",
    "    else:\n",
    "        last_index = -1\n",
    "    \n",
    "    batch_start_index = last_index + 1\n",
    "    batch_end_index = batch_start_index + macro_batch_size\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    iterable = itertools.islice(dataloader, batch_start_index, batch_end_index)\n",
    "\n",
    "    Path(\"temp\").mkdir(exist_ok=True)\n",
    "    for batch_index, batch in enumerate(tqdm(iterable, total=macro_batch_size), start=batch_start_index):\n",
    "        batch_logits = model.forward(batch.to(device))\n",
    "        pd.DataFrame(batch_logits.cpu().detach().numpy()).to_csv(\n",
    "            Path(\"temp\") / f\"logits_batch_{batch_size}_{batch_index}.csv\",\n",
    "            index=False,\n",
    "            header=False\n",
    "        )\n",
    "    upload_files_to_datastore(\"workspaceblobstore\", predictions_directory, \"temp\", \"*.csv\")\n",
    "    shutil.rmtree(\"temp\", ignore_errors=True)\n",
    "        \n",
    "\n",
    "@make_command\n",
    "def main(job_name, model_download_path, data_path, audio_files_csv, audio_files_folder, predictions_path):\n",
    "    audio_files_folder = Path(data_path) / audio_files_folder\n",
    "    audio_files_csv = audio_files_csv\n",
    "    \n",
    "    audio_files = pd.read_csv(str(audio_files_csv)).iloc[:, 0].map(\n",
    "        lambda path: str(Path(audio_files_folder) / path)\n",
    "    )\n",
    "    \n",
    "    detector_loaded = get_model(job_name, model_download_path)\n",
    "    dumb_dataset = AudioDumbDataset(audio_files, 16000, 64000)\n",
    "    predict_macro_batch(detector_loaded, dumb_dataset, predictions_path, batch_size=10, macro_batch_size=10)\n",
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b15e7f-c01c-4afb-aef1-88ce5b11fe33",
   "metadata": {},
   "source": [
    "## Test script locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46769ef7-1eb8-4b1d-b8dd-d3b68f89cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.modules.pop(\"audio_binary_dataset\", None)\n",
    "# sys.modules.pop(\"cloned_audio_detector\", None)\n",
    "# sys.modules.pop(\"utils\", None)\n",
    "# sys.modules.pop(\"predict\", None)\n",
    "\n",
    "# # predictions_path = directory_structure.training_artifacts_path / \"predictions\"\n",
    "# # predictions_path.mkdir(exist_ok=True)\n",
    "# audio_files_csv = \"temp/selected.csv\"\n",
    "\n",
    "# with mounted_data_asset(name=\"CommonVoiceDeltaSegment15\", label=\"latest\") as common_voice_mount_path:\n",
    "#     with WorkingDirectoryOn(project_source_path):\n",
    "#         with relative_paths_from(\n",
    "#             project_source_path,\n",
    "#             [\n",
    "#                 # predictions_path,\n",
    "#                 directory_structure.models_path,\n",
    "#                 audio_files_csv,\n",
    "#             ]\n",
    "#         ) as (\n",
    "#             # predictions_path_relative,\n",
    "#             model_download_path,\n",
    "#             audio_files_csv_relative,\n",
    "#         ):\n",
    "#             with cli_arguments(\n",
    "#                 job_name=\"dynamic_yacht_mgxs2hytb1\",\n",
    "#                 model_download_path=model_download_path,\n",
    "#                 data=common_voice_mount_path,\n",
    "#                 audio_files_csv=audio_files_csv_relative,\n",
    "#                 audio_files_folder=\"en/clips/\",\n",
    "#                 predictions_path=\"Predictions/CommonVoiceDelta15\"\n",
    "#             ):\n",
    "#                 runpy.run_path(f\"predict.py\", run_name='__main__')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8f772-e129-44f0-8c60-b7eaa1ccbce3",
   "metadata": {},
   "source": [
    "## Create component definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c19954-3df5-49a5-b016-f13deafeab17",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1de5f96-96d9-4916-9599-dca362b5f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_environment_name = \"predict-environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbb8794a-9318-4c2b-9ee3-1a273077967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job_definitions/environments/predict-environment.yaml'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%rendertemplate {directory_structure.environments_path}/{predict_environment_name}.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: [[predict_environment_name]]\n",
    "image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n",
    "conda_file: conda.yaml\n",
    "description: Environment created for data preparation in voice classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbbca91-dd30-423f-862a-d8dfe244f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az ml environment create --file {directory_structure.environments_path}/{predict_environment_name}.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff70c1a-c570-48a5-83a3-3dc16fead167",
   "metadata": {},
   "source": [
    "### Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "928ed1c6-48e0-4c4f-a493-215a64c7abaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job_definitions/classification_wav2vec/prediction_job.yaml'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%rendertemplate {pipeline_path}/prediction_job.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "name: predict\n",
    "display_name: Predict audio file type\n",
    "\n",
    "code: [[project_source_path_relative]]\n",
    "command: >-\n",
    "    python predict.py \n",
    "    --job_name=${{inputs.job_name}}\n",
    "    --model_download_path=\"model\"\n",
    "    --data_path=${{inputs.audio_dataset}}\n",
    "    --audio_files_csv=${{inputs.files_csv}}\n",
    "    --audio_files_folder=${{inputs.audio_files_folder}}\n",
    "    --predictions_path=${{inputs.predictions_path}}\n",
    "\n",
    "inputs:\n",
    "    job_name:\n",
    "        type: string\n",
    "    audio_dataset:\n",
    "        type: uri_folder\n",
    "        mode: ro_mount\n",
    "    files_csv:\n",
    "        type: uri_file\n",
    "        mode: ro_mount\n",
    "    audio_files_folder:\n",
    "        type: string\n",
    "    predictions_path:\n",
    "        type: string\n",
    "        \n",
    "environment: azureml:[[predict_environment_name]]@latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e7b04-4f2b-463b-8cd3-674c82aea67e",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af778241-186a-46eb-9a89-bcc7a30c9e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job_definitions/classification_wav2vec/prediction_pipeline.yaml'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%rendertemplate {pipeline_path}/prediction_pipeline.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "type: pipeline\n",
    "\n",
    "experiment_name: ClonedVoiceDetectorPrediction\n",
    "display_name: ClonedVoiceDetectorPrediction\n",
    "description: Pipeline for cloned voice detection prediction\n",
    "\n",
    "settings:\n",
    "    # default_compute: azureml:[[cheap_compute_name]]\n",
    "    default_compute: azureml:compute-cluster\n",
    "    \n",
    "inputs:\n",
    "    common_voice_dataset:\n",
    "        type: uri_folder\n",
    "        path: azureml:CommonVoiceDeltaSegment15@latest\n",
    "        mode: ro_mount\n",
    "    training_job_name: \"dynamic_yacht_mgxs2hytb1\"\n",
    "\n",
    "jobs:\n",
    "    prepare_audio_files:\n",
    "        type: command\n",
    "        component: [[prepare_data_component_name]]\n",
    "        inputs:\n",
    "            common_voice_dataset: ${{parent.inputs.common_voice_dataset}}\n",
    "            files_info_tsv: \"en/validated.tsv\"\n",
    "        outputs:\n",
    "            audio_files_csv:\n",
    "                mode: upload\n",
    "    predict:\n",
    "        type: command\n",
    "        component: prediction_job.yaml\n",
    "        inputs:\n",
    "            job_name: ${{parent.inputs.training_job_name}}\n",
    "            audio_dataset: ${{parent.inputs.common_voice_dataset}}\n",
    "            files_csv: ${{parent.jobs.prepare_audio_files.outputs.audio_files_csv}}\n",
    "            audio_files_folder: \"en/clips/\"\n",
    "            predictions_path: \"Predictions/CommonVoiceDelta15\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958ff0f-8664-4865-a107-26b8647aa76e",
   "metadata": {},
   "source": [
    "# Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb5893b-8d9b-4a7a-98af-ec8932a2466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading classification_wav2vec (0.03 MBs): 100%|█| 25023/25023 [00:00<00:00, 3\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-11-12T17:28:50.472045+00:00\",\n",
      "    \"created_by\": \"Rubén Chuliá Mena Chuliá Mena\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Pipeline for cloned voice detection prediction\",\n",
      "  \"display_name\": \"ClonedVoiceDetectorPrediction\",\n",
      "  \"experiment_name\": \"ClonedVoiceDetectorPrediction\",\n",
      "  \"id\": \"azureml:/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourceGroups/apzivaresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/apzivaproject6workspace/jobs/silly_tree_6p1bfzf05k\",\n",
      "  \"inputs\": {\n",
      "    \"common_voice_dataset\": {\n",
      "      \"mode\": \"ro_mount\",\n",
      "      \"path\": \"azureml:CommonVoiceDeltaSegment15:1\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    },\n",
      "    \"training_job_name\": \"dynamic_yacht_mgxs2hytb1\"\n",
      "  },\n",
      "  \"jobs\": {\n",
      "    \"predict\": {\n",
      "      \"component\": \"azureml:azureml_anonymous:9fb6108d-c593-4600-ad6d-f7c4825b1a6f\",\n",
      "      \"inputs\": {\n",
      "        \"audio_dataset\": {\n",
      "          \"path\": \"${{parent.inputs.common_voice_dataset}}\"\n",
      "        },\n",
      "        \"audio_files_folder\": \"en/clips/\",\n",
      "        \"files_csv\": {\n",
      "          \"path\": \"${{parent.jobs.prepare_audio_files.outputs.audio_files_csv}}\"\n",
      "        },\n",
      "        \"job_name\": {\n",
      "          \"path\": \"${{parent.inputs.training_job_name}}\"\n",
      "        },\n",
      "        \"predictions_path\": \"Predictions/CommonVoiceDelta15\"\n",
      "      },\n",
      "      \"type\": \"command\"\n",
      "    },\n",
      "    \"prepare_audio_files\": {\n",
      "      \"component\": \"azureml:azureml_anonymous:5fdf07ae-1a07-4b28-9415-8c5a3d4ff425\",\n",
      "      \"inputs\": {\n",
      "        \"common_voice_dataset\": {\n",
      "          \"path\": \"${{parent.inputs.common_voice_dataset}}\"\n",
      "        },\n",
      "        \"files_info_tsv\": \"en/validated.tsv\"\n",
      "      },\n",
      "      \"outputs\": {\n",
      "        \"audio_files_csv\": {\n",
      "          \"mode\": \"upload\",\n",
      "          \"type\": \"uri_file\"\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"command\"\n",
      "    }\n",
      "  },\n",
      "  \"name\": \"silly_tree_6p1bfzf05k\",\n",
      "  \"properties\": {\n",
      "    \"azureml.DatasetAccessMode\": \"Asset\",\n",
      "    \"azureml.DevPlatv2\": \"true\",\n",
      "    \"azureml.continue_on_failed_optional_input\": \"True\",\n",
      "    \"azureml.continue_on_step_failure\": \"True\",\n",
      "    \"azureml.defaultComputeName\": \"compute-cluster\",\n",
      "    \"azureml.defaultDataStoreName\": \"workspaceblobstore\",\n",
      "    \"azureml.enforceRerun\": \"False\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"azureml.parameters\": \"{\\\"training_job_name\\\":\\\"dynamic_yacht_mgxs2hytb1\\\"}\",\n",
      "    \"azureml.pipelineComponent\": \"pipelinerun\",\n",
      "    \"azureml.runsource\": \"azureml.PipelineRun\",\n",
      "    \"mlflow.source.git.branch\": \"cleaning\",\n",
      "    \"mlflow.source.git.commit\": \"10d2dedc14fc6a12403d939fbac6d4b0c66d75b9\",\n",
      "    \"mlflow.source.git.repoURL\": \"git@github.com:rubchume/VoiceCloningFakeAudioDetection.git\",\n",
      "    \"runSource\": \"MFE\",\n",
      "    \"runType\": \"HTTP\"\n",
      "  },\n",
      "  \"resourceGroup\": \"apzivaresourcegroup\",\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/silly_tree_6p1bfzf05k?wsid=/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourcegroups/apzivaresourcegroup/workspaces/apzivaproject6workspace&tid=f4d1e53e-b4af-49af-a80f-55fd817818d9\",\n",
      "      \"type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourceGroups/apzivaresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/apzivaproject6workspace?\",\n",
      "      \"type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"settings\": {\n",
      "    \"default_compute\": \"azureml:compute-cluster\"\n",
      "  },\n",
      "  \"status\": \"Preparing\",\n",
      "  \"type\": \"pipeline\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file {pipeline_path}/prediction_pipeline.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicecloningenv",
   "language": "python",
   "name": "voicecloningenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
