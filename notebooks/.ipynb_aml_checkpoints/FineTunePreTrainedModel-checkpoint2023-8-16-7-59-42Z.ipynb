{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2a5062-fb8f-45f0-bb10-a7caf2f675fc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3eb708-3ca0-4a2f-8b02-bb4c2b49005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53d0f38-82d0-4756-88a6-b12d3ee223be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import runpy\n",
    "import shutil\n",
    "import sys\n",
    "import wave\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from tqdm.notebook import tqdm\n",
    "from TTS.api import TTS\n",
    "from TTS.tts.configs.shared_configs import BaseAudioConfig, BaseDatasetConfig\n",
    "\n",
    "import directory_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52635560-a4a7-4406-988e-1cb4b473cb82",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca3104e-6cd4-4018-9eaa-d63d933a2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_token = \"KsRAhfqgNyld8zhGt9QqXutULWJgFDCn6Qv7o3ZT0eUXRSvv9JIbf31cY0MYAdhj\"\n",
    "os.environ[\"COQUI_STUDIO_TOKEN\"] = api_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111646d1-afc6-4185-bff4-2f38f9861544",
   "metadata": {},
   "source": [
    "# Choose model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17849e-293d-461e-a50e-9916289a7341",
   "metadata": {},
   "source": [
    "List models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ff7c5c5-1add-445e-8577-a35d42fef4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS().list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0630e-02be-4863-8512-fe0eebbb1620",
   "metadata": {},
   "source": [
    "Choose some candidates and a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a56e5e3-5e96-444e-8b3f-4feb704a4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"tts_models/spa/fairseq/vits\",\n",
    "    \"tts_models/es/mai/tacotron2-DDC\",\n",
    "    \"coqui_studio/multilingual/Eva 1/XTTS\",\n",
    "]\n",
    "\n",
    "sentence = \"Hola guapa. Soy tu clon. A partir de ahora Rubén podrá escuchar tu voz diciendo lo que él quiera. Por ejemplo, puedo decirle siempre que quiera escucharlo, qué más pues mor?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e91519-f7f8-4b25-9062-8c499a6eb9ef",
   "metadata": {},
   "source": [
    "Synthesize the sentence with all the models and listen to all of them to choose the model you most like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de2889e-c9bb-4f67-8249-ade470d7a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# for model in tqdm(models):\n",
    "#     tts = TTS(model_name=model, progress_bar=False)\n",
    "#     tts.tts_to_file(\n",
    "#         sentence,\n",
    "#         file_path=f'outputs/{model.replace(\"/\", \"-\")}.wav'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ca1c6-ac6d-4159-b639-fb71eb1a17bd",
   "metadata": {},
   "source": [
    "Find the model weights file and config JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196f5499-2755-4f2c-b878-2f57b1c73745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/azureuser/.local/share/tts/tts_models--es--css10--vits/model_file.pth.tar\"\n",
    "config_path= \"/home/azureuser/.local/share/tts/tts_models--es--css10--vits/config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247793e-af59-4136-9742-76df8763af2e",
   "metadata": {},
   "source": [
    "Synthesize the test sentence with the model to see that the model weights and config path still generate the same audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ba0e12-29fe-444b-8b5b-417750dbdbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# tts = TTS(model_path=model_path, config_path=config_path, progress_bar=False)\n",
    "# tts.tts_to_file(text=sentence, file_path=\"example_output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94565bdf-6059-4363-90cd-a89b8d52fd2f",
   "metadata": {},
   "source": [
    "# Prepare config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9387f9-fd51-4d60-ab2f-ce55f0583803",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"EvaFineTuneCss10Vits\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254fdb65-6fa6-49e6-8120-bb67ef8a6d46",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06004605-ed40-4907-bb4d-9d999553faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file):\n",
    "    return json.loads(Path(json_file).read_text())\n",
    "\n",
    "\n",
    "def write_json(json_file, dictionary):\n",
    "    Path(json_file).write_text(json.dumps(dictionary))\n",
    "\n",
    "\n",
    "class ModelConfigToUpdate:\n",
    "    def __init__(self, path, new_path=None, safe=True):\n",
    "        if safe:\n",
    "            if new_path is None or path == new_path:\n",
    "                raise ValueError(\"The new path cannot be the same as the original one\")\n",
    "        \n",
    "        self.path = path\n",
    "        self.new_path = new_path\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.config_dict = read_json(config_path)\n",
    "        return self.config_dict\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        new_path = self.new_path or self.path\n",
    "        write_json(new_path, self.config_dict)\n",
    "        \n",
    "        \n",
    "def get_relative_path(origin, destination):\n",
    "    go_up_path = \"../\"\n",
    "    \n",
    "    origin_absolute = Path(origin).resolve()\n",
    "    destination_absolute = Path(destination).resolve()\n",
    "    \n",
    "    common_path = Path(os.path.commonpath([origin_absolute, destination_absolute]))\n",
    "    from_origin_to_common_path = Path(go_up_path * (len(origin_absolute.parts) - len(common_path.parts)))\n",
    "    from_common_path_to_destination = destination_absolute.relative_to(common_path)\n",
    "    return from_origin_to_common_path / from_common_path_to_destination\n",
    "\n",
    "\n",
    "class WorkingDirectoryOn:\n",
    "    def __init__(self, working_directory):\n",
    "        self.working_directory = working_directory\n",
    "        self.original_working_directory = os.getcwd()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        os.chdir(self.working_directory)\n",
    "    \n",
    "    def __exit__(self, exception_type, exception_instance, traceback):\n",
    "        os.chdir(self.original_working_directory)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def cli_arguments(**arguments):\n",
    "    original_arguments = sys.argv\n",
    "    sys.argv = kwargs_to_command_line_arguments(**arguments)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.argv = original_arguments\n",
    "\n",
    "\n",
    "def kwargs_to_command_line_arguments(**kwargs):\n",
    "    return [None] + list(itertools.chain.from_iterable([\n",
    "        (f\"--{key}\", str(value))\n",
    "        for key, value in kwargs.items()\n",
    "    ]))\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def relative_paths_from(origin, paths):\n",
    "    yield (\n",
    "        get_relative_path(origin, path)\n",
    "        for path in paths\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4daff85-907f-473d-8438-cd59e2371c24",
   "metadata": {},
   "source": [
    "Rewrite configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87666bf5-3795-462e-9a3d-e38e7b7f8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = directory_structure.source_path / experiment_name\n",
    "overriden_config_path = Path(source_folder_path) / \"overriden_config.json\"\n",
    "overriden_speaker_ids_path = Path(source_folder_path) / \"speaker_ids.json\"\n",
    "source_folder_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b36e66b-e3d2-47dd-8405-85539f6d4794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relative_path(\"src\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a58f9d2a-d1a1-47bd-b5d5-5a703caed9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    ModelConfigToUpdate(config_path, overriden_config_path) as config_dictionary,\n",
    "    relative_paths_from(\"src\", [\"data\", overriden_speaker_ids_path]) as (data_rel, speaker_ids_rel)\n",
    "):\n",
    "    config_dictionary[\"output_path\"] = \"training_output\"\n",
    "    \n",
    "    dataset_config = BaseDatasetConfig(\n",
    "        meta_file_train=\"eva_transcript.txt\",\n",
    "        path=str(data_rel),\n",
    "        language=\"es\",\n",
    "        formatter=\"custom_formatter\"\n",
    "    )\n",
    "    config_dictionary[\"datasets\"] = [vars(dataset_config)]\n",
    "    \n",
    "    write_json(overriden_speaker_ids_path, {\"Eva\": 0})\n",
    "    config_dictionary[\"model_args\"][\"speakers_file\"] = str(speaker_ids_rel)\n",
    "    \n",
    "    config_dictionary[\"test_sentences\"] = [\n",
    "        \"Hola me llamo Eva\",\n",
    "        \"Soy la clon de su voz. En qué puedo ayudarte?\",\n",
    "    ]\n",
    "    del config_dictionary[\"datasets\"][0][\"_initialized\"]\n",
    "    \n",
    "    config_dictionary[\"model_args\"][\"init_discriminator\"] = True\n",
    "    config_dictionary[\"max_audio_len\"] = 2000000\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba667e-4c2e-4120-85bb-e402d26c8d76",
   "metadata": {},
   "source": [
    "# Upload pretrained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664ee181-269e-47ce-8d63-1b735c3d9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.copy(model_path, source_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a12bd87-f70a-4ed5-adcb-7dea1391c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_name = \"Css10VitsModelWeights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4791f0f-5479-4486-a3eb-a82ef53b4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model_weights = Data(\n",
    "#     path=model_path,\n",
    "#     type=AssetTypes.URI_FILE,\n",
    "#     description=\"Model weights of tts_models--es--css10--vits\",\n",
    "#     name=model_weights_name,\n",
    "#     version=\"1\"\n",
    "# )\n",
    "\n",
    "# ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
    "# ml_client.data.create_or_update(pretrained_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d7371-be89-4b37-b522-fd386113c5d5",
   "metadata": {},
   "source": [
    "# Create training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9779d-74a4-40f5-9e91-b80a19c1d459",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2a9b1-34a8-40a7-ac41-5c1cbd911f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv = [\n",
    "#     None,\n",
    "#     \"--config_path\", \n",
    "#     str(overriden_config_path),\n",
    "#     \"--restore_path\",\n",
    "#     model_path\n",
    "# ]\n",
    "\n",
    "# from src.custom_formatter import custom_formatter\n",
    "# from TTS.tts import datasets\n",
    "\n",
    "\n",
    "# datasets.custom_formatter = custom_formatter\n",
    "# try:\n",
    "#     runpy.run_module(\"TTS.bin.train_tts\", run_name='__main__')\n",
    "# except Exception:\n",
    "#     import pdb\n",
    "#     pdb.post_mortem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "def182ea-a5dd-440c-8b5d-417a244f70a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/EvaFineTuneCss10Vits/train_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {source_folder_path}/train_script.py\n",
    "import runpy\n",
    "\n",
    "from custom_formatter import custom_formatter\n",
    "from TTS.tts import datasets\n",
    "\n",
    "\n",
    "def main():\n",
    "    datasets.custom_formatter = custom_formatter\n",
    "    runpy.run_module(\"TTS.bin.train_tts\", run_name='__main__', alter_sys=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7bfb07-f67f-4509-87e5-8e57a3b649f1",
   "metadata": {},
   "source": [
    "Try train script in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55e559e7-7411-4bb5-a96d-9febd7ae48d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7307db81-6fb3-4e6c-86c0-f566cb0a3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection\n"
     ]
    }
   ],
   "source": [
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13d4c1d5-a58c-4638-a3a5-6146c0176402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('EvaFineTuneCss10Vits/overriden_config.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5232a334-a8ef-43d9-a54e-e9657a34eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 128 files in /mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection/data\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Num. of CPUs: 2\n",
      " | > Num. of Torch Threads: 2\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=training_output/-September-16-2023_05+46AM-f52bb74\n",
      " > Restoring from model_file.pth.tar ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > `speakers.pth` is saved to training_output/-September-16-2023_05+46AM-f52bb74/speakers.pth.\n",
      " > `speakers_file` is updated in the config.json.\n",
      " > `language_ids.json` is saved to training_output/-September-16-2023_05+46AM-f52bb74/language_ids.json.\n",
      " > `language_ids_file` is updated in the config.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Restoring Model...\n",
      " > Partial model initialization...\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.0.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.1.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.2.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.3.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.4.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.convs.5.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.0.conv_post.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.0.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.1.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.2.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.3.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.1.convs.4.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.1.conv_post.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.0.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.1.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.2.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.3.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.2.convs.4.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.2.conv_post.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.0.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.1.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.2.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.3.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.3.convs.4.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.3.conv_post.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.0.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.1.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.2.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.3.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.4.convs.4.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.4.conv_post.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.0.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.1.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.2.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.3.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.5.convs.4.weight_v\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.bias\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.weight_g\n",
      " | > Layer missing in the checkpoint: disc.nets.5.conv_post.weight_v\n",
      " | > 696 / 807 layers are restored.\n",
      " > Model restored from step 470000\n",
      "/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\n",
      " > Model has 73823776 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> training_output/-September-16-2023_05+46AM-f52bb74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 127\n",
      "> \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection/TTS/TTS/tts/datasets/dataset.py\u001b[0m(347)\u001b[0;36mpreprocess_samples\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    345 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m    346 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 347 \u001b[0;31m        \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    348 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    349 \u001b[0;31m        \u001b[0;31m# sort items based on the sequence length in ascending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "\u001b[1m > TRAINING (2023-09-16 05:46:57) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 273\n",
      " | > Min text length: 7\n",
      " | > Avg text length: 180.23622047244095\n",
      " | \n",
      " | > Max audio length: 1536022.0\n",
      " | > Min audio length: 110758.0\n",
      " | > Avg audio length: 1457827.7322834646\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "y, ¿oli rubén qué tal cómo estás? yo, ahora mi primer día en el trabajo, todo bien, de momento, voy ahora a comer y después vuelvo porque me toca todavía algunas clases administrativas y todo. todo está bien, lo que pasa es que no,\n",
      " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
      "lo importante que era para ti, así que eso. y sí, lo de la fiesta, hombre, yo este año, es mi primer año, bueno, desde yo, participo en esta fiesta desde mis quince, ¿vale? cuando era\n",
      " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
      "octubre de noviembre, no de septiembre, ¿sabes?, que el crime no era eso, no era así, así que también llamamos días raros, pero a partir de hoy creo que se mejorará,\n",
      " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
      "vale, ¿qué plan es tienes para mañana rubén? cuéntame.\n",
      " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
      "me tenéis ahí, vale? en octubre, porque si no me volvó lo que era en casa de lo juro. es que rued es una puta mierda, eh. como peleamos con mi mamá en todo, en todo. ¡joder! ella me dirige...\n",
      " [!] Character '¡' not found in the vocabulary. Discarding it.\n",
      "me encanta demasiado, ¿sabes? pero amor, ¿sabes? ¡madre, mi hijo! pero tiene buena pinta, eh. las fotos, las fotos molan. es que no conozco este.\n",
      " [!] Character '¡' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "--Return--\n",
      "tensor([[[ 6....ionBackward0>)\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/nn/modules/conv.py\u001b[0m(309)\u001b[0;36m_conv_forward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    307 \u001b[0;31m                            \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    308 \u001b[0;31m                            _single(0), self.dilation, self.groups)\n",
      "\u001b[0m\u001b[0;32m--> 309 \u001b[0;31m        return F.conv1d(input, weight, bias, self.stride,\n",
      "\u001b[0m\u001b[0;32m    310 \u001b[0;31m                        self.padding, self.dilation, self.groups)\n",
      "\u001b[0m\u001b[0;32m    311 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[0;32m/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\u001b[0m(419)\u001b[0;36mselect\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    417 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    418 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 419 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_event_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    420 \u001b[0;31m            \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    421 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_EVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd5ed035bd0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      " ! Run is kept in training_output/-September-16-2023_05+46AM-f52bb74\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1808, in fit\n",
      "    self._fit()\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1760, in _fit\n",
      "    self.train_epoch()\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1488, in train_epoch\n",
      "    outputs, _ = self.train_step(batch, batch_num_steps, cur_step, loader_start_time)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1369, in train_step\n",
      "    outputs, loss_dict_new, step_time = self.optimize(\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1212, in optimize\n",
      "    outputs, loss_dict = self._compute_loss(\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1141, in _compute_loss\n",
      "    outputs, loss_dict = self._model_train_step(batch, model, criterion, optimizer_idx=optimizer_idx)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/trainer/trainer.py\", line 1102, in _model_train_step\n",
      "    return model.train_step(*input_args)\n",
      "  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection/TTS/TTS/tts/models/vits.py\", line 1255, in train_step\n",
      "    outputs = self.forward(\n",
      "  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection/TTS/TTS/tts/models/vits.py\", line 1021, in forward\n",
      "    z, m_q, logs_q, y_mask = self.posterior_encoder(y, y_lengths, g=g)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection/TTS/TTS/tts/layers/vits/networks.py\", line 284, in forward\n",
      "    x = self.enc(x, x_mask, g=g)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/rubchume1/code/Users/rubchume/VoiceCloningFakeAudioDetection/TTS/TTS/tts/layers/generic/wavenet.py\", line 100, in forward\n",
      "    x_in = self.in_layers[i](x)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 313, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 309, in _conv_forward\n",
      "    return F.conv1d(input, weight, bias, self.stride,\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/bdb.py\", line 94, in trace_dispatch\n",
      "    return self.dispatch_return(frame, arg)\n",
      "  File \"/anaconda/envs/voicecloningenv/lib/python3.10/bdb.py\", line 156, in dispatch_return\n",
      "    if self.quitting: raise BdbQuit\n",
      "bdb.BdbQuit\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with (\n",
    "    WorkingDirectoryOn(\"src\"),\n",
    "    cli_arguments(\n",
    "        config_path=get_relative_path(\"src\", overriden_config_path),\n",
    "        restore_path=f\"{experiment_name}/model_file.pth.tar\"\n",
    "    )\n",
    "):\n",
    "    runpy.run_module(f\"{experiment_name}.train_script\", run_name='__main__', alter_sys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40548e27-d5ca-4624-84d0-c6c1afa2e816",
   "metadata": {},
   "source": [
    "# Job definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "090bdd04-3e29-4249-805d-3caeb01651c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_path = directory_structure.job_definitions_path / experiment_name\n",
    "Path(job_path).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e30a50bb-3eab-4559-bb02-6a48aba3494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_key_pair_path = directory_structure.job_definitions_path / \"ssh_key_pair\"\n",
    "public_key = ssh_key_pair_path.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dce1c35-fbe9-48cb-a5cc-f3ceabcdb25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = \"compute-cluster-gpu\"\n",
    "environment_name = \"voice-cloning-job-environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "856c66bb-30cd-4109-ac92-cc3fd0b3c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = get_relative_path(origin=job_path, destination=directory_structure.source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adf26a9a-3b0b-4f04-955b-1ad65ea863ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_overriden_config_path = get_relative_path(origin=directory_structure.source_path, destination=overriden_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f65fd78-e7dd-4a84-af1b-98416b3d33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%rendertemplate {job_path}/job.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "\n",
    "experiment_name: {experiment_name}\n",
    "description: \"The fine tuning of pretrained VITS for cloning Eva's voice\"\n",
    "\n",
    "compute: azureml:{compute_name}\n",
    "environment: azureml:{environment_name}@latest\n",
    "code: {code_path}\n",
    "command: >-\n",
    "    python -m {experiment_name}.train_script\n",
    "    --config_path ${{inputs.config_path}}\n",
    "    --restore_path ${{inputs.pretrained_model_weights}}\n",
    "    --coqpit.epochs ${{inputs.epochs}}\n",
    "\n",
    "inputs:\n",
    "    config_path: {relative_overriden_config_path}\n",
    "    pretrained_model_weights:\n",
    "        type: uri_file\n",
    "        path: azureml:{model_weights_name}:1\n",
    "    epochs: 10\n",
    "\n",
    "services:\n",
    "    my_tensor_board:\n",
    "        type: tensor_board\n",
    "        log_dir: \"training_output\"\n",
    "        nodes: all\n",
    "    my_ssh:\n",
    "        type: ssh\n",
    "        ssh_public_keys: \"{public_key}\"\n",
    "        nodes: all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3e7f9-4676-4407-aa7d-ccb9661484ad",
   "metadata": {},
   "source": [
    "# Run job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "578ead76-77d5-4b87-9475-965c7e92db3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{\\ Finished ..\n",
      "  \"description\": \"GPU compute cluster\",\n",
      "  \"enable_node_public_ip\": true,\n",
      "  \"id\": \"/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourceGroups/apzivaresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/apzivaproject6workspace/computes/compute-cluster-gpu\",\n",
      "  \"idle_time_before_scale_down\": 180,\n",
      "  \"location\": \"westeurope\",\n",
      "  \"max_instances\": 2,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"compute-cluster-gpu\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"apzivaresourcegroup\",\n",
      "  \"size\": \"STANDARD_NC4AS_T4_V3\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --file {directory_structure.computes_path}/{compute_name}.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31afbad3-7489-4010-af52-0bc977fe0ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Use of {} for parameters is deprecated, instead use ${{}}.\n",
      "{\n",
      "  \"code\": \"azureml:/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourceGroups/apzivaresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/apzivaproject6workspace/codes/2760d92e-0f4a-44e7-8c2c-563163734195/versions/1\",\n",
      "  \"command\": \"python -m EvaFineTuneCss10Vits.train_script --config_path $${{inputs.config_path}} --restore_path $${{inputs.pretrained_model_weights}} --coqpit.epochs $${{inputs.epochs}}\",\n",
      "  \"compute\": \"azureml:compute-cluster-gpu\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2023-09-16T05:54:32.148598+00:00\",\n",
      "    \"created_by\": \"Rubén Chuliá Mena Chuliá Mena\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"The fine tuning of pretrained VITS for cloning Eva's voice\",\n",
      "  \"display_name\": \"polite_office_s4vxrfzy5y\",\n",
      "  \"environment\": \"azureml:voice-cloning-job-environment:12\",\n",
      "  \"environment_variables\": {},\n",
      "  \"experiment_name\": \"EvaFineTuneCss10Vits\",\n",
      "  \"id\": \"azureml:/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourceGroups/apzivaresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/apzivaproject6workspace/jobs/polite_office_s4vxrfzy5y\",\n",
      "  \"inputs\": {\n",
      "    \"config_path\": \"EvaFineTuneCss10Vits/overriden_config.json\",\n",
      "    \"epochs\": \"10\",\n",
      "    \"pretrained_model_weights\": {\n",
      "      \"mode\": \"ro_mount\",\n",
      "      \"path\": \"azureml:Css10VitsModelWeights:1\",\n",
      "      \"type\": \"uri_file\"\n",
      "    }\n",
      "  },\n",
      "  \"name\": \"polite_office_s4vxrfzy5y\",\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.polite_office_s4vxrfzy5y\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {},\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"6c181b84-2049-4b03-9c92-6229804c94b2\",\n",
      "    \"_azureml.ComputeTargetType\": \"amlctrain\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"mlflow.source.git.branch\": \"tts-voice-cloning\",\n",
      "    \"mlflow.source.git.commit\": \"f52bb741dcfdce4731e0fc2ca763ede7a9fa49ed\",\n",
      "    \"mlflow.source.git.repoURL\": \"git@github.com:rubchume/VoiceCloningFakeAudioDetection.git\"\n",
      "  },\n",
      "  \"resourceGroup\": \"apzivaresourcegroup\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 1,\n",
      "    \"properties\": {},\n",
      "    \"shm_size\": \"2g\"\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/polite_office_s4vxrfzy5y?wsid=/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourcegroups/apzivaresourcegroup/workspaces/apzivaproject6workspace&tid=f4d1e53e-b4af-49af-a80f-55fd817818d9\",\n",
      "      \"type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/c3771bb2-164a-4abc-a91d-4f2c9b4652cc/resourceGroups/apzivaresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/apzivaproject6workspace?\",\n",
      "      \"type\": \"Tracking\"\n",
      "    },\n",
      "    \"my_ssh\": {\n",
      "      \"properties\": {},\n",
      "      \"type\": \"ssh\"\n",
      "    },\n",
      "    \"my_tensor_board\": {\n",
      "      \"log_dir\": \"training_output\",\n",
      "      \"properties\": {\n",
      "        \"logDir\": \"training_output\"\n",
      "      },\n",
      "      \"type\": \"tensor_board\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Starting\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"command\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file {job_path}/job.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicecloningenv",
   "language": "python",
   "name": "voicecloningenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
